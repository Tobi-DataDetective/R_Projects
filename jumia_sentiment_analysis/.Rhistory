myplot(MinutesPlayed)
myplot(Points)
myplot(MinutesPlayed)
myplot(Points)
myplot(FieldGoals/Games)
myplot(FieldGoals/FieldGoalAttempts)
myplot(FieldGoalAttempts/Games)
myplot(Points/Games)
myplot(MinutesPlayed/Games)
myplot(games)
myplot(Games)
myplot(FieldGoals/MinutesPlayed)
myplot(Points/FieldGoals)
#freethrow insights
myplot2(freethrow)
myplot2<-function(dara,rowl=1:10){
data2<-dara[rowl,]
matplot(t(data2),type="b",pch=15:16,col = c(1:4,6))
legend("bottomleft",inset = 0.001 ,legend = Players[rowl],pch=15:18,col = c(1:4,6),horiz = F)
}
#freethrow insights
myplot2(freethrow)
#basketball insight
myplot(Salary)
myplot <- function(datas,rows=1:10){
data <- datas[rows,]
matplot(t(data),type = "b",pch = 15:16,col = c(1:4,6))
legend("bottomleft", inset = 0.001,legend = Players[rows],pch = 15:16,col = c(1:4,6) )
}
#basketball insight
myplot(Salary)
myplot(Salary/Games)
myplot(Salary/FieldGoals)
#basketball insight
myplot(Salary)
data
data['2005']
data.frame(freethrow,freethrowattempts)
Games
c(data,Games)
new<-c(data,Games)
head(new)
data
rm(new)
new\
data
data.frame(Games)
df<-data.frame(Games)
new<- c(data,Games)
new
freethrowattempts# <put your code here>
mtcars
mtcars$mpg
mtcars[mtcars$mpg]
mtcars[,mtcars$mpg]
mtcars[mtcars$mpg,]
mtcars$mpg
mtcars['mpg']
colnames(mtcars)
rownames(mtcars)
mtcars$mpg
mtcars[mtcars$mpg]
mtcars[[mtcars$mpg]]
mtcars[mtcars$mpg,]
mtcars[,mtcars$mpg]
mtcars[[mtcars$mpg,]]
mtcars
mtcars["Fiat 128",mpg]
mtcars["Fiat 128","drat"]
mtcars[,'mpg']
mtcars["Fiat 128","drat",drop=F]
mtcars$mpg
mtcars$mpg,drop=F
mtcars['mpg', drop=F]
myplot(Salary/FieldGoals)
myplot(MinutesPlayed)
myplot(Games)
#visualizing with matplot
FieldGoals
fg<- t(FieldGoals)
fg
matplot(fg)
matplot(fg, type = "b", pch = 15:18, col = c(1:4,6))
legend("bottomleft",inset = 0.01, legend = Players, col = c(1:4,6),pch = 15:18, horiz = F)
#subsetting
Games
Games[1:3,6:10]
Games[c(1,10),]
Games[1,,drop=F]
#visualizing susetting
MinutesPlayed
data<-MinutesPlayed[1:3,]
data
matplot(t(data),type = "b",pch = 15:18,col = c(1:4,6))
legend("bottomleft",inset = 0.01, legend = Players[1:3],col = c(1:4,6),pch = 15:18)
#creating first function
myplot <- function(datas,rows=1:10){
data <- datas[rows,]
matplot(t(data),type = "b",pch = 15:16,col = c(1:4,6))
legend("bottomleft", inset = 0.001,legend = Players[rows],pch = 15:16,col = c(1:4,6) )
}
myplot(MinutesPlayed,1:5)
#basketball insight
myplot(Salary)
myplot(Salary/Games)
myplot(Salary/FieldGoals)
myplot(MinutesPlayed)
myplot(Points)
myplot(FieldGoals/Games)
myplot(FieldGoals/FieldGoalAttempts)
myplot(FieldGoalAttempts/Games)
myplot(Points/Games)
myplot(MinutesPlayed/Games)
myplot(Games)
myplot(FieldGoals/MinutesPlayed)
myplot(Points/FieldGoals)
install.packages("twitteR")
install.packages("C:/Users/Folayan Tobi/Downloads/R library/ggplot2_3.1.0.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Folayan Tobi/Downloads/R library/ggplot2_3.1.0.tar.gz", repos = NULL, type = "source")
install.packages("C:/Users/Folayan Tobi/Downloads/R library/ggplot2_3.1.0.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Folayan Tobi/Downloads/R library/dplyr_0.8.0.1.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Folayan Tobi/Downloads/R library/httr_1.4.0.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Folayan Tobi/Downloads/R library/plyr_1.8.4.zip", repos = NULL, type = "win.binary")
library("ggplot2", lib.loc="~/R/win-library/3.5")
install.packages("C:/Users/Folayan Tobi/Downloads/R library/RCurl_1.95-4.11.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Folayan Tobi/Downloads/R library/ROAuth_0.9.6.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Folayan Tobi/Downloads/R library/RSentiment_2.2.2.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Folayan Tobi/Downloads/R library/sentiment_0.1.tar.gz", repos = NULL, type = "source")
install.packages("C:/Users/Folayan Tobi/Downloads/R library/stringr_1.4.0.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Folayan Tobi/Downloads/R library/stringr_1.4.0.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Folayan Tobi/Downloads/R library/tm_0.7-6.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Folayan Tobi/Downloads/R library/twitteR_1.1.9.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Folayan Tobi/Downloads/R library/wordcloud_2.6.zip", repos = NULL, type = "win.binary")
install.packages("C:/Users/Folayan Tobi/Downloads/R library/wordcloud2_0.2.1.zip", repos = NULL, type = "win.binary")
# load library
library(twitteR)
twitteR::
library("ggplot2", lib.loc="~/R/win-library/3.5")
library(ggplot2)
remove.packages("dplyr", lib="~/R/win-library/3.5")
remove.packages("ggplot2", lib="~/R/win-library/3.5")
remove.packages("httr", lib="~/R/win-library/3.5")
remove.packages("plyr", lib="~/R/win-library/3.5")
remove.packages("RCurl", lib="~/R/win-library/3.5")
remove.packages("ROAuth", lib="~/R/win-library/3.5")
remove.packages("RSentiment", lib="~/R/win-library/3.5")
remove.packages("stringr", lib="~/R/win-library/3.5")
remove.packages("tm", lib="~/R/win-library/3.5")
remove.packages("twitteR", lib="~/R/win-library/3.5")
remove.packages("wordcloud", lib="~/R/win-library/3.5")
remove.packages("wordcloud2", lib="~/R/win-library/3.5")
install.packages("twitteR")
install.packages("ROAuth")
install.packages("ggplot2")
install.packages("tm")
install.packages("plyr")
install.packages("dplyr")
# load library
library(twitteR)
library(tm)
library(ggplot2)
.libPaths()
library(plyr)
install.packages("twitteR")
library("twitteR", lib.loc="~/R/win-library/3.5")
detach("package:twitteR", unload=TRUE)
# load library
library(twitteR)
install.packages("C:/Users/Folayan Tobi/AppData/Local/Temp/RtmpCoP140/downloaded_packages/twitteR_1.1.9.zip", repos = NULL, type = "win.binary")
install.packages("RoAuth")
install.packages("RoAuth")
yes
install.packages("ROAuth")
install.packages("plyr")
library("plyr", lib.loc="~/R/win-library/3.5")
detach("package:plyr", unload=TRUE)
install.packages("dplyr")
install.packages("stringr")
install.packages("ggplot2")
install.packages("httr")
install.packages("wordcloud")
install.packages("wordcloud2")
install.packages("wordcloud2")
install.packages("sentimentr")
install.packages("SentimentAnalysis")
install.packages("RCurl")
install.packages("tm")
install.packages("shiny")
install.packages("RODBC")
setwd("C:/Users/Folayan Tobi/Documents/videos/sentiment project")
jumia<-read.csv("C:/Users/Folayan Tobi/Documents/videos/sentiment project/jumia/jumia.csv")
View(jumia)
str(jumia)
library(twitteR)
library(ROAuth)
library(plyr)
library(dplyr)
library(stringr)
library(ggplot2)
library(httr)
library(wordcloud)
library(SnowballC)
library(RColorBrewer)
#library(sentiment)
library(RCurl)
library(tm)
library(tm)
library(twitteR)
##########building corpus########
corpus<- iconv(jumia$text)
#remove retweets
corpus[1:5]
corpus<- gsub("(RT|via)((?:\\b\\w*@\\w+)+)"," ",corpus)
#remove people
corpus<- gsub("@\\w+"," ",corpus)
corpus<- gsub("\n.*"," ",corpus) #removes every \n pattern
corpus
#removing html link
#corpus<- gsub("http\\w+","",corpus)
######creating a corpus###############
corpus<- Corpus(VectorSource(corpus))
inspect(corpus[1:5])
################cleaning text#####################
corpus<-tm_map(corpus,tolower)
inspect(corpus[1:5])
corpus<-tm_map(corpus,removePunctuation)
corpus<-tm_map(corpus,removeNumbers)
cleanset<- tm_map(corpus, removeWords,stopwords('english'))
inspect(cleanset[1:5])
removeURL <- function(x) gsub('http[[:alnum:]]*',' ',x)
cleanset<- tm_map(cleanset,content_transformer(removeURL))
cleanset<- tm_map(cleanset,removeWords,c('jumia','rt','leggend'))
#cleanset<- tm_map(cleanset,PlainTextDocument)
cleanset<- tm_map(cleanset,stemDocument)
cleanset<- tm_map(cleanset, gsub,
pattern ='deliveri',
replace = 'deliv')
cleanset<- tm_map(cleanset, gsub,
pattern ='â€¦',
replace = '')
cleanset<-tm_map(cleanset,stripWhitespace)
###########Term document matrix##########
tdm<- TermDocumentMatrix(cleanset)
tdm<- as.matrix(tdm)
tdm[1:10,1:10]
#########Bar plot########
freq<-rowSums(tdm)
freq<-subset(freq,freq>=25)
freq
barplot(freq,
las = 2,
col = rainbow(40))
########wordcloud###########
library(wordcloud)
wc<-sort(rowSums(tdm), decreasing = TRUE)
wc
set.seed(222)
wordcloud(words = names(wc), freq = wc>=14)
wordcloud(words = names(wc), freq = (wc>=14))
rm(wc)
w <- sort(rowSums(tdm), decreasing = TRUE)
########wordcloud###########
library(wordcloud)
w <- sort(rowSums(tdm), decreasing = TRUE)
wordcloud(words = names(w), freq = w, max.words = 100)
barplot(freq,
las = 2,
col = rainbow(40))
wordcloud(words = names(w), freq = w, max.words = 100)
wordcloud(words = names(w), freq = w)
wordcloud(words = names(w), freq = w, max.words = 150)
wordcloud(words = names(w), freq = w, max.words = 150,
random.order = F, min.freq = 5)
wordcloud(words = names(w), freq = w, max.words = 150,
random.order = F, min.freq = 5)
wordcloud(words = names(w), freq = w, max.words = 150,
random.order = F, min.freq = 5,
colors = brewer.pal(8,'Dark2'))
wordcloud(words = names(w), freq = w, max.words = 150,
random.order = F, min.freq = 5,
colors = brewer.pal(8,'Dark2'))
wordcloud(words = names(w), freq = w, max.words = 150,
random.order = F, min.freq = 5,
colors = brewer.pal(6,'Dark2'))
wordcloud(words = names(w), freq = w, max.words = 150,
random.order = F, min.freq = 5,
colors = brewer.pal(6,'Dark2'),
scale = c(7,0.3))
wordcloud(words = names(w), freq = w, max.words = 150,
random.order = F, min.freq = 5,
colors = brewer.pal(6,'Dark2'),
scale = c(7,0.3))
wordcloud(words = names(w), freq = w, max.words = 150,
random.order = F, min.freq = 5,
colors = brewer.pal(6,'Dark2'),
scale = c(7,0.1))
wordcloud(words = names(w), freq = w, max.words = 150,
random.order = F, min.freq = 5,
colors = brewer.pal(6,'Dark2'),
scale = c(7,0.5))
wordcloud(words = names(w), freq = w, max.words = 150,
random.order = F, min.freq = 5,
colors = brewer.pal(6,'Dark2'),
scale = c(7,1))
wordcloud(words = names(w), freq = w, max.words = 150,
random.order = F, min.freq = 5,
colors = brewer.pal(6,'Dark2'),
scale = c(7,0.2))
wordcloud(words = names(w), freq = w, max.words = 150,
random.order = F, min.freq = 5,
colors = brewer.pal(6,'Dark2'))
wordcloud(words = names(w), freq = w, max.words = 150,
random.order = F, min.freq = 5,
colors = brewer.pal(6,'Dark2'),
scale = c(5,0.3))
wordcloud(words = names(w), freq = w, max.words = 150,
random.order = F, min.freq = 5,
colors = brewer.pal(6,'Dark2'),
scale = c(5,0.3),
rot.per = 0.3)
w
##########wordcloud2##########
w <- data.frame(names(w), w)
w
colnames(w) <- c('word','freq')
head(w)
wordcloud(words = word, freq = freq, max.words = 150,
random.order = F, min.freq = 5,
colors = brewer.pal(6,'Dark2'),
scale = c(5,0.3),
rot.per = 0.3)
##########wordcloud2##########
library(wordcloud2)
w <- data.frame(names(w), w)
w
colnames(w) <- c('word','freq')
head(w)
wordcloud2(w,
size = 0.8,
shape = 'circle')
wordcloud2(w,
size = 0.8,
shape = 'circle')
head(w)
w <- sort(rowSums(tdm), decreasing = TRUE)
##########wordcloud2##########
library(wordcloud2)
w <- data.frame(names(w), w)
w
colnames(w) <- c('word','freq')
head(w)
wordcloud2(w,
size = 0.8,
shape = 'circle')
wordcloud2(w,
size = 0.2,
shape = 'circle')
wordcloud2(w,
size = 0.5,
shape = 'circle')
w
wordcloud2(w,
size = 0.5,
shape = 'star',
rotateRatio = 0.5,
minSize = 1)
wordcloud2(w,
size = 0.5,
shape = 'A',
rotateRatio = 0.5,
minSize = 1)
wordcloud2(w,
size = 0.5,
shape = 'A',
rotateRatio = 0.5,
minSize = 1)
wordcloud2(w,
size = 0.5,
shape = 'a',
rotateRatio = 0.5,
minSize = 1)
letterCloud(w,wordSize = 0.2,letterFont = 'jumia')
letterCloud(w,word = 'jumia', size=1)
letterCloud(w,word = 'jumia')
letterCloud(w,word = 'j', size=1)
wordcloud2(w,
size = 0.5,
shape = 'a',
rotateRatio = 0.5,
minSize = 1)
letterCloud(w, word = 'A', size = 1)
letterCloud(w, word = 'A', size = 2)
letterCloud(w, word = 'A', size = 0.2)
letterCloud(w, word = "a", size = 0.2)
letterCloud(w, word = "a", size = 1)
wordcloud2(w,
size = 0.5,
shape = 'a',
rotateRatio = 0.5,
minSize = 1)
wordcloud2(w,
size = 0.5,
shape = 'triangle',
rotateRatio = 0.5,
minSize = 1)
letterCloud(w, word = "A", wordSize = 1)
letterCloud(w, word = "jumia")
wordcloud2(w,
size = 0.5,
shape = 'circle',
rotateRatio = 0.5,
minSize = 1)
letterCloud(w, word = "A", size = 2)
letterCloud(w, word = "b", size = 2)
letterCloud(w, word = "y", size = 2)
##########wordcloud2##########
library(wordcloud2)
letterCloud(w, word = "A", size = 2)
wordcloud2(w,
size = 0.5,
shape = 'circle',
rotateRatio = 0.5,
minSize = 1)
letterCloud(w, word = "a", size = 2)
?letterCloud
letterCloud(w, "a")
wordcloud2(w,
size = 0.5,
shape = 'circle',
rotateRatio = 0.5,
minSize = 1)
install.packages("lubridate")
library(syuzhet)
library(lubridate)
library(ggplot2)
library(scales)
library(reshape2)
library(dplyr)
library(syuzhet)
library(lubridate)
library(ggplot2)
library(scales)
library(reshape2)
library(dplyr)
library(syuzhet)
library(lubridate)
library(ggplot2)
library(scales)
library(reshape2)
library(dplyr)
setwd("C:/Users/Folayan Tobi/Documents/videos/sentiment project")
jumia<-read.csv("C:/Users/Folayan Tobi/Documents/videos/sentiment project/jumia/jumia.csv")
tweets<- iconv(jumia$text)
sent<- get_nrc_sentiment(tweets)
head(sent)
sent[5]
tweets[5]
head(sent)
tweets[4]
tweets[5]
tweets[2]
tweets[6]
#####barplot#######
barplot(colSums(sent),
las = 2,
col = rainbow(20),
ylab = 'Count',
xlab = 'expression',
main = 'JUMIA SENTIMENT SCORES')
#####barplot#######
barplot(colSums(sent),
las = 2,
col = rainbow(20),
ylab = 'Count',
main = 'JUMIA SENTIMENT SCORES')
############positve neg normal##########
setwd("C:/Users/Folayan Tobi/Documents/videos/sentiment project/jumia")
opinion.lexicon.pos<- scan('positive-words.txt',what = 'character', comment.char = ';')
opinion.lexicon.neg<- scan('negative-words.txt',what = 'character', comment.char = ';')
jj<- str_split(corpus,pattern = "\\s+")
jj
u<-lapply(jj,function(x){!is.na(match(x, opinion.lexicon.pos))})
v<-lapply(jj,function(x){!is.na(match(x, opinion.lexicon.neg))})
score<- u-v
score
u
rm(u)
rm(v)
sum(!is.na(match(jj, opinion.lexicon.pos)))
u<-lapply(jj,function(x){!is.na(match(x, opinion.lexicon.pos))})
sum(u)
jj
jj
lapply(jj,FUN = paste, collapse)
sum(!is.na(match(jj, opinion.lexicon.pos)))
sum(!is.na(match(jj, opinion.lexicon.neg)))
jj<- str_split(cleanset,pattern = "\\s+")
jj<- str_split(cleanset,pattern = "\\s+")
jj
jj<- str_split(tdm,pattern = "\\s+")
jj
sum(!is.na(match(jj, opinion.lexicon.pos)))
corpus
corpus
jj<- str_split(corpus,pattern = "\\s+")
jj
u<-lapply(jj,function(x){sum(!is.na(match(x, opinion.lexicon.pos))}))
jj
u<- lapply(jj, function(x){sum(!is.na(match(jj,opinion.lexicon.pos)))})
v<- lapply(jj, function(x){sum(!is.na(match(jj,opinion.lexicon.neg)))})
u
v
